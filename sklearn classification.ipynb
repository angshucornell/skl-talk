{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classification in Scikit-Learn\n",
      "\n",
      "This is the IPython notebook for classification in scikit-learn that accompanies the \"A Beginner's Guide to Machine Learning with Scikit-Learn\" I gave at PyData NYC 2013 and will also be giving at PyTennessee 2014. The slides can be found at http://www.slideshare.net/SarahGuido/a-beginners-guide-to-machine-learning-with-scikitlearn. \n",
      "\n",
      "This is a fairly simple example. I'm thinking about adding more examples with other classifiers.\n",
      "\n",
      "If you have questions, corrections, or suggestions for doing any of this in a better, more Pythonic way, please contact me.\n",
      "\n",
      "### Some Good Things to Know\n",
      "\n",
      "The first thing to know is that the scikit-learn estimators take in continuous data only. I'm working with categorical data from the Car Evaluation dataset, so I have to transform these categorical values into continuous values.\n",
      "\n",
      "Another thing to know is that the process for almost everything we do is the same: create an object, fit it to data, and do something with it (predict, encode, binarize, etc).\n",
      "\n",
      "### Getting Data into Scikit-Learn\n",
      "\n",
      "There are multiple ways of importing data to scikit-learn. One of the easiest ways I've found for categorical data is to read in a file from a csv and put it into a list of dictionaries, which can easily be encoded into 1s and 0s in sklearn. For the target variables, that simply gets read into a list and is then encoded."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "car_data = list(csv.DictReader(open('cardata.csv', 'rU')))\n",
      "car_target = list(csv.reader(open('cartarget.csv', 'rU')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's what the first dictionary in the list looks like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "car_data[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "{'buying': 'vhigh',\n",
        " 'doors': '2',\n",
        " 'lug_boot': 'small',\n",
        " 'maint': 'vhigh',\n",
        " 'persons': '4',\n",
        " 'safety': 'med'}"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step in vectorizing our categorical values is to create a DictVectorizer() object and then use fit_transform() and toarray() to get the values into a NumPy array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "vec = DictVectorizer()\n",
      "car_data = vec.fit_transform(car_data).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a vectorized item and the unencoded item beneath."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Vectorized:', car_data[10]\n",
      "print 'Unvectorized:', vec.inverse_transform(car_data[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorized: [ 0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.\n",
        "  0.  0.  1.]\n",
        "Unvectorized: [{'persons=4': 1.0, 'buying=vhigh': 1.0, 'safety=med': 1.0, 'lug_boot=small': 1.0, 'doors=2': 1.0, 'maint=vhigh': 1.0}]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because the labels are also categorical, those need to be transformed as well. There's a special LabelEncoder() object specifically for this task."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "\n",
      "le = preprocessing.LabelEncoder()\n",
      "le.fit([\"unacc\", \"acc\", \"good\", \"vgood\"])\n",
      "target = le.transform(car_target[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's the transformed label and what it means."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Transformed:', target[10] \n",
      "print 'Inverse transformed:', le.inverse_transform(target[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Transformed: 2\n",
        "Inverse transformed: unacc\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Splitting Up the Dataset\n",
      "\n",
      "Another preprocessing step is to split up the dataset, in order to avoid overfitting. The train_test_split() function is a really simple way to do that. By default, the size of the test set is 25%."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "car_data_train, car_data_test, target_train, target_test = train_test_split(car_data, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The length of the whole data set is 1728 instances. After train_test_split():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Training set:', len(car_data_train)\n",
      "print 'Test set:', len(car_data_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set: 1296\n",
        "Test set: 432\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Naive Bayes Classification\n",
      "\n",
      "Now we're ready for classification. The Naive Bayes classifier assumes that the features are independent, which is a naive assumption. The classifier performs decently, but is fairly simple. \n",
      "\n",
      "To build the classifier, first create the model by setting a variable equal to the Naive Bayes object. The GaussianNB() estimator assumes a normal distribution. Then, fit the model to the training dataset and the training labels. Finally, predict on a new set of data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "nb_estimator = GaussianNB()\n",
      "nb_estimator.fit(car_data_train, target_train)\n",
      "pred = nb_estimator.predict(car_data_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comparing the first 8 predicted labels to what the first 8 labels actually are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Predicted labels:', pred[0:8]\n",
      "print 'Actual labels:', target_test[0:8]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicted labels: [2 2 1 2 2 2 3 1]\n",
        "Actual labels: [2 2 0 2 2 2 0 2]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's the text values of the labels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Predicted labels:', list(le.inverse_transform(pred[0:8]))\n",
      "print 'Actual labels:', list(le.inverse_transform(target_test[0:8]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicted labels: ['unacc', 'unacc', 'good', 'unacc', 'unacc', 'unacc', 'vgood', 'good']\n",
        "Actual labels: ['unacc', 'unacc', 'acc', 'unacc', 'unacc', 'unacc', 'acc', 'unacc']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Testing and Validation\n",
      "\n",
      "As you can see, the classifier got a few labels wrong. There are a few methods of determining how accurate the model is. The simplest is the score() function, which compares predicted labels to actual labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nb_estimator.score(car_data_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0.79166666666666663"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another method for testing the accuracy of the estimator is cross-validation, which splits up the dataset randomly and computes the accuracy of the model by comparing predicted labels to the actual labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "\n",
      "cross_validation.cross_val_score(nb_estimator, car_data_test, target_test, cv=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array([ 0.84259259,  0.75925926,  0.80555556,  0.76851852])"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's pretty much it! For now, at least."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}