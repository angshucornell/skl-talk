{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Preprocessing in Scikit-Learn\n",
      "\n",
      "This is the IPython notebook for data preprocessing in scikit-learn that accompanies the \"A Beginner's Guide to Machine Learning with Scikit-Learn\" I gave at PyData NYC 2013 and will also be giving at PyTennessee 2014. The slides can be found at http://www.slideshare.net/SarahGuido/a-beginners-guide-to-machine-learning-with-scikitlearn. \n",
      "\n",
      "This is a fairly simple example. I'm thinking about adding more examples with other classifiers.\n",
      "\n",
      "If you have questions, corrections, or suggestions for doing any of this in a better, more Pythonic way, please contact me.\n",
      "\n",
      "### Some Good Things to Know\n",
      "\n",
      "The first thing to know is that the scikit-learn estimators take in continuous data only. I'm working with categorical data from the Car Evaluation dataset, so I have to transform these categorical values into continuous values.\n",
      "\n",
      "Another thing to know is that the process for almost everything we do is the same: create an object, fit it to data, and do something with it (predict, encode, binarize, etc).\n",
      "\n",
      "### Getting Data into Scikit-Learn\n",
      "\n",
      "There are multiple ways of importing data to scikit-learn. One of the easiest ways I've found for categorical data is to read in a file from a csv and put it into a list of dictionaries, which can easily be encoded into 1s and 0s in sklearn. For the target variables, that simply gets read into a list and is then encoded."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "car_data = list(csv.DictReader(open('../cardata.csv', 'rU')))\n",
      "car_target = list(csv.reader(open('../cartarget.csv', 'rU')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's what the first dictionary in the list looks like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "car_data[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "{'buying': 'vhigh',\n",
        " 'doors': '2',\n",
        " 'lug_boot': 'small',\n",
        " 'maint': 'vhigh',\n",
        " 'persons': '4',\n",
        " 'safety': 'med'}"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step in vectorizing our categorical values is to create a DictVectorizer() object and then use fit_transform() and toarray() to get the values into a NumPy array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "vec = DictVectorizer()\n",
      "car_data = vec.fit_transform(car_data).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a vectorized item and the unencoded item beneath."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Vectorized:', car_data[10]\n",
      "print 'Unvectorized:', vec.inverse_transform(car_data[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorized: [ 0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.\n",
        "  0.  0.  1.]\n",
        "Unvectorized: [{'persons=4': 1.0, 'buying=vhigh': 1.0, 'safety=med': 1.0, 'lug_boot=small': 1.0, 'doors=2': 1.0, 'maint=vhigh': 1.0}]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because the labels are also categorical, those need to be transformed as well. There's a special LabelEncoder() object specifically for this task."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "\n",
      "le = preprocessing.LabelEncoder()\n",
      "le.fit([\"unacc\", \"acc\", \"good\", \"vgood\"])\n",
      "target = le.transform(car_target[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's the transformed label and what it means."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Transformed:', target[10] \n",
      "print 'Inverse transformed:', le.inverse_transform(target[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Transformed: 2\n",
        "Inverse transformed: unacc\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Splitting Up the Dataset\n",
      "\n",
      "Another preprocessing step is to split up the dataset, in order to avoid overfitting. The train_test_split() function is a really simple way to do that. By default, the size of the test set is 25%."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "car_data_train, car_data_test, target_train, target_test = train_test_split(car_data, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The length of the whole data set is 1728 instances. After train_test_split():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Training set:', len(car_data_train)\n",
      "print 'Test set:', len(car_data_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set: 1296\n",
        "Test set: 432\n"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}