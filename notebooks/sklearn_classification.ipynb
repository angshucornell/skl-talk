{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classification in Scikit-Learn\n",
      "\n",
      "This is the IPython notebook for classification in scikit-learn that accompanies the \"A Beginner's Guide to Machine Learning with Scikit-Learn\" I gave at PyData NYC 2013 and will also be giving at PyTennessee 2014. The slides can be found at http://www.slideshare.net/SarahGuido/a-beginners-guide-to-machine-learning-with-scikitlearn. \n",
      "\n",
      "This is a fairly simple example. I'm thinking about adding more examples with other classifiers.\n",
      "\n",
      "If you have questions, corrections, or suggestions for doing any of this in a better, more Pythonic way, please contact me.\n",
      "\n",
      "### Some Good Things to Know\n",
      "\n",
      "The first thing to know is that the scikit-learn estimators take in continuous data only. I'm working with categorical data from the Car Evaluation dataset, so I have to transform these categorical values into continuous values.\n",
      "\n",
      "Another thing to know is that the process for almost everything we do is the same: create an object, fit it to data, and do something with it (predict, encode, binarize, etc).\n",
      "\n",
      "### Naive Bayes Classification\n",
      "\n",
      "Hopefully you've first read through the sklearn_preprocessing notebook. If so, you're now ready to build your classifier. The Naive Bayes classifier assumes that the features are independent, which is a naive assumption. The classifier performs decently, but is fairly simple. \n",
      "\n",
      "To build the classifier, first create the model by setting a variable equal to the Naive Bayes object. The GaussianNB() estimator assumes a normal distribution. Then, fit the model to the training dataset and the training labels. Finally, predict on a new set of data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "nb_estimator = GaussianNB()\n",
      "nb_estimator.fit(car_data_train, target_train)\n",
      "pred = nb_estimator.predict(car_data_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comparing the first 8 predicted labels to what the first 8 labels actually are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Predicted labels:', pred[0:8]\n",
      "print 'Actual labels:', target_test[0:8]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicted labels: [2 2 1 2 2 2 3 1]\n",
        "Actual labels: [2 2 0 2 2 2 0 2]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's the text values of the labels:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Predicted labels:', list(le.inverse_transform(pred[0:8]))\n",
      "print 'Actual labels:', list(le.inverse_transform(target_test[0:8]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicted labels: ['unacc', 'unacc', 'good', 'unacc', 'unacc', 'unacc', 'vgood', 'good']\n",
        "Actual labels: ['unacc', 'unacc', 'acc', 'unacc', 'unacc', 'unacc', 'acc', 'unacc']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's pretty much it! For now, at least."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}